<!DOCTYPE html>
<html lang="id">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Virtual Try-On Anak</title>
  <style>
    body { margin:0; display:flex; flex-direction:column; align-items:center; }
    #container { position:relative; width:100%; max-width:400px; aspect-ratio:3/4; }
    video, canvas { position:absolute; width:100%; height:100%; object-fit:cover; }
    #baju { position:absolute; pointer-events:none; transform-origin:top center; }
    #controls { margin-top:10px; }
    select { padding:6px; font-size:14px; }
  </style>
</head>
<body>
  <div id="container">
    <video id="video" autoplay playsinline muted></video>
    <canvas id="canvas"></canvas>
    <img id="baju" src="baju1.png" alt="Baju">
  </div>
  <div id="controls">
    <select id="cameraSelect"></select>
  </div>

  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/pose@0.5/pose.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/camera_utils/camera_utils.js"></script>
  <script>
    const video = document.getElementById("video");
    const canvas = document.getElementById("canvas");
    const ctx = canvas.getContext("2d");
    const baju = document.getElementById("baju");
    const cameraSelect = document.getElementById("cameraSelect");
    let currentStream, camera;

    const pose = new Pose({
      locateFile: (file) => `https://cdn.jsdelivr.net/npm/@mediapipe/pose@0.5/${file}`,
    });
    pose.setOptions({
      modelComplexity: 1,
      smoothLandmarks: true,
      enableSegmentation: false,
      minDetectionConfidence: 0.5,
      minTrackingConfidence: 0.5,
    });

    pose.onResults((results) => {
      canvas.width = video.videoWidth;
      canvas.height = video.videoHeight;
      ctx.clearRect(0, 0, canvas.width, canvas.height);

      if (results.poseLandmarks) {
        const lm = results.poseLandmarks;
        const ls = lm[11], rs = lm[12], lh = lm[23], rh = lm[24];
        if (ls && rs && lh && rh) {
          const shoulderWidth = Math.abs((rs.x - ls.x) * canvas.width);
          const torsoHeight = Math.abs((lh.y - ls.y) * canvas.height);
          const centerX = ((ls.x + rs.x) / 2) * canvas.width;
          const topY = (ls.y * canvas.height) - 40;

          const bajuWidth = shoulderWidth * 2;
          const bajuHeight = torsoHeight * 1.5;
          baju.style.width = bajuWidth + "px";
          baju.style.height = bajuHeight + "px";
          baju.style.left = (centerX - bajuWidth / 2) + "px";
          baju.style.top = topY + "px";
        }
      }
    });

    async function startCamera(deviceId) {
      if (currentStream) {
        currentStream.getTracks().forEach(track => track.stop());
      }
      try {
        currentStream = await navigator.mediaDevices.getUserMedia({
          video: { deviceId: { exact: deviceId } }
        });
        video.srcObject = currentStream;

        if (camera) camera.stop();
        camera = new Camera(video, {
          onFrame: async () => {
            await pose.send({ image: video });
          },
          width: 400,
          height: 600,
        });
        camera.start();
      } catch (err) {
        console.error("Gagal start kamera:", err);
      }
    }

    async function loadCameras() {
      const devices = await navigator.mediaDevices.enumerateDevices();
      const videoDevices = devices.filter(d => d.kind === "videoinput");

      cameraSelect.innerHTML = "";
      videoDevices.forEach((device, i) => {
        const option = document.createElement("option");
        option.value = device.deviceId;
        option.text = device.label || `Kamera ${i+1}`;
        cameraSelect.appendChild(option);
      });

      if (videoDevices[0]) {
        startCamera(videoDevices[0].deviceId);
      }
    }

    cameraSelect.addEventListener("change", () => {
      startCamera(cameraSelect.value);
    });

    loadCameras();
  </script>
</body>
</html>
